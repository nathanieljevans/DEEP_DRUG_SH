{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Baseline \n",
    "\n",
    "This model will be built using **only** beatAML data to predict AUC. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build our data loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DrugExpressionDataset(Dataset): \n",
    "    ''' '''\n",
    "    \n",
    "    def __init__ (self, label_dict, root_dir = '../pytorch_data/'): \n",
    "        '''\n",
    "        '''\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, val = (0.7,0.15,0.15)\n",
    "\n",
    "with open('../data_pytorch/label_dict.pkl', 'rb') as f: \n",
    "    label_dict = pickle.load(f)\n",
    "\n",
    "label_dict2 = dict()\n",
    "for fid in label_dict: \n",
    "    _id, id_type, resp_type, response = label_dict[fid]\n",
    "    \n",
    "    if resp_type not in label_dict2: \n",
    "        label_dict2[resp_type] = dict()\n",
    "        \n",
    "    p = np.random.rand()\n",
    "    if (p < train): # add to training set \n",
    "        if 'train' in label_dict2[resp_type]: \n",
    "            label_dict2[resp_type]['train'][fid] = (_id, id_type, resp_type, response)\n",
    "        else:\n",
    "            label_dict2[resp_type]['train'] = {fid:(_id, id_type, resp_type, response)}\n",
    "\n",
    "    elif (p < train+test): # add to test set \n",
    "        if 'test' in label_dict2[resp_type]: \n",
    "            label_dict2[resp_type]['test'][fid] = (_id, id_type, resp_type, response)\n",
    "        else:\n",
    "            label_dict2[resp_type]['test'] = {fid:(_id, id_type, resp_type, response)}\n",
    "    else: # add to validation set \n",
    "        if 'val' in label_dict2[resp_type]: \n",
    "            label_dict2[resp_type]['val'][fid] = (_id, id_type, resp_type, response)\n",
    "        else:\n",
    "            label_dict2[resp_type]['val'] = {fid:(_id, id_type, resp_type, response)}            \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['RNAi_dependency', 'crispr_dependency', 'pooled_drugresp_prism', 'AUC_GDSC', 'CTRP_AUC', 'AUC_drug_CCLE', 'beatAML_AUC'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set sizes: RNAi_dependency      \t-> train  \t-> 217733\n",
      "set sizes: RNAi_dependency      \t-> test  \t-> 46755\n",
      "set sizes: RNAi_dependency      \t-> val  \t-> 46707\n",
      "set sizes: crispr_dependency    \t-> val  \t-> 46645\n",
      "set sizes: crispr_dependency    \t-> train  \t-> 219596\n",
      "set sizes: crispr_dependency    \t-> test  \t-> 46735\n",
      "set sizes: pooled_drugresp_prism \t-> train  \t-> 107884\n",
      "set sizes: pooled_drugresp_prism \t-> test  \t-> 23121\n",
      "set sizes: pooled_drugresp_prism \t-> val  \t-> 23188\n",
      "set sizes: AUC_GDSC             \t-> train  \t-> 16910\n",
      "set sizes: AUC_GDSC             \t-> test  \t-> 3643\n",
      "set sizes: AUC_GDSC             \t-> val  \t-> 3595\n",
      "set sizes: CTRP_AUC             \t-> val  \t-> 4229\n",
      "set sizes: CTRP_AUC             \t-> train  \t-> 19532\n",
      "set sizes: CTRP_AUC             \t-> test  \t-> 4217\n",
      "set sizes: AUC_drug_CCLE        \t-> train  \t-> 1635\n",
      "set sizes: AUC_drug_CCLE        \t-> test  \t-> 383\n",
      "set sizes: AUC_drug_CCLE        \t-> val  \t-> 362\n",
      "set sizes: beatAML_AUC          \t-> train  \t-> 1823\n",
      "set sizes: beatAML_AUC          \t-> test  \t-> 394\n",
      "set sizes: beatAML_AUC          \t-> val  \t-> 408\n"
     ]
    }
   ],
   "source": [
    "for resp_type in label_dict2:\n",
    "    for sset in label_dict2[resp_type]: \n",
    "        pp = resp_type + ' '*(20 - len(resp_type))\n",
    "        print(f'set sizes: {pp} \\t-> {sset}  \\t-> {len(label_dict2[resp_type][sset])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining our model architecture \n",
    "\n",
    "Going to use a straight forward 4 layer FFFC network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, ngenes, sz=(250,100,10), do=0.3):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        H1, H2, H3 = sz\n",
    "        self.do = torch.nn.Dropout(do)\n",
    "        self.fc1 = nn.Linear(ngenes, H1)\n",
    "        self.bn1 = nn.BatchNorm1d(H1)\n",
    "        self.fc2 = nn.Linear(H1, H2)\n",
    "        self.bn2 = nn.BatchNorm1d(H2)\n",
    "        self.fc3 = nn.Linear(H2, H3)\n",
    "        self.bn3 = nn.BatchNorm1d(H3)\n",
    "        self.out = nn.Linear(H3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        z1 = self.do( self.fc1(x) )\n",
    "        z1 = self.bn1( z1 )\n",
    "        a1 = F.relu(z1)\n",
    "        z2 = self.do( self.fc2(a1) )\n",
    "        z2 = self.bn2( z2 )\n",
    "        a2 = F.relu(z2)\n",
    "        z3 = self.do( self.fc3(a2) )\n",
    "        z3 = self.bn3( z3 )\n",
    "        a3 = F.relu(z3)\n",
    "        zo = self.out(a3)\n",
    "        o = self.softmax(zo)\n",
    "        \n",
    "        return o\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

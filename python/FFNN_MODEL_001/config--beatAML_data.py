###############################################################################
###############################################################################
###############################################################################
'''
THIS IS THE BEATAML ONLY CONFIG FILE
'''
###############################################################################
###############################################################################
###############################################################################

params = {
'NAME' : 'BEATAML-DATA-006',

# -----------------------------------------------------------------------------
# -----------------------------------------------------------------------------
'DATA_DIR' : '../../data_pytorch/tensors/',
'LABEL_PATH' : '../../data_pytorch/label_dict.pkl',
'SPLIT_LABEL_PATH' : '../../data_pytorch/split_label_dict.pkl',
'MODEL_OUT_DIR' : '../../models/',
# -----------------------------------------------------------------------------
# -----------------------------------------------------------------------------
'RESPLIT_DATA' : False,
'TRAIN_PROP' : 0.7,
'TEST_PROP' : 0.15,
'VAL_PROP' : 0.15,
'N_BEATAML_PATIENTS_EXCLUSIVE_TO_TEST' : 30  ,          # remove patients for test
# -----------------------------------------------------------------------------
# -----------------------------------------------------------------------------
'SAVE_MODEL_EVERY' : 10, # epochs
'PRINT_MID_EPOCH_INFO' : False,
# -----------------------------------------------------------------------------
# -----------------------------------------------------------------------------
    ## `i` indicates the order of classification layers
'RESP_TYPES' : {x:i for i,x in enumerate(['beatAML_AUC'])},

'H1' : 2000,
'H2' : 2000,
'H3' : 500,                # Layer 3 - Dataset Shared
'DH' : 100,                # Dataset Specific Layer

'DO' : 0.5,                # Dropout
'NCONVS' : 10,
'PRINT_EVERY' : 1,
'NGENES' : 523, #/ 523
'EPOCHS' : 200,
'LEARNING_WEIGHT' : 1e-1,
'WEIGHT_DECAY' : 0.1,
'LR_DECAY_PATIENCE' : 75,       # batches (not epochs)

'PRETRAIN_EPOCHS' : 5,
'PRETRAIN_LR' : 1e-2,
'PRETRAIN_WD' : 0.2,
'PRETRAIN_DO' : 0.9,
'PRETRAIN_MSE_WEIGHT' : 50,     # Weight applied to target MSE
# -----------------------------------------------------------------------------
# -----------------------------------------------------------------------------
'REPRODUCIBLE' : False,
'SEED' : 1000,

# -----------------------------------------------------------------------------
# -----------------------------------------------------------------------------
'train_params' : {'batch_size': 1024,
          'shuffle': True,
          'num_workers': 12},

'test_params' : {'batch_size': 512,
          'shuffle': False,
          'num_workers': 12}
}
